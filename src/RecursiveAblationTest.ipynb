{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "from inference import unload_model, run_experiment_batch\n",
    "from RefusalVectors import load_prompts, get_full_block_activations, get_refusal_vectors, save_candidate_vectors, safety_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368d6551",
   "metadata": {},
   "source": [
    "## Load Model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/gpt-oss-20b\"\n",
    "\n",
    "def load_model(model_name):\n",
    "    device = \"cuda\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, \n",
    "        trust_remote_code=True,\n",
    "        # device_map=\"auto\",   # Hugging Face accelerates across multiple GPUs\n",
    "        dtype=\"auto\"   # or torch.float16 / bfloat16\n",
    "    ).to(device)\n",
    "    return model, tokenizer, device\n",
    "\n",
    "model, tokenizer, device = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Global configuration ====\n",
    "N_CLEAN_TEST = 50\n",
    "N_HARM_TEST = 100\n",
    "N_HARM_TRAIN = 150\n",
    "N_CLEAN_TRAIN = 200\n",
    "N_MALICIOUS_TRAIN = 50\n",
    "\n",
    "# ==== Data loading ====\n",
    "harm_train, clean_train = load_prompts(\n",
    "    harm_range=range(N_HARM_TRAIN),\n",
    "    alpaca_range=range(N_CLEAN_TRAIN),\n",
    "    malicious_range=range(N_MALICIOUS_TRAIN),\n",
    ")\n",
    "\n",
    "harm_test, clean_test = load_prompts(\n",
    "    harm_range=range(N_HARM_TRAIN + 1, N_HARM_TRAIN + 1 + N_HARM_TEST // 2),\n",
    "    alpaca_range=range(N_CLEAN_TRAIN + 1, N_CLEAN_TRAIN + 1 + N_CLEAN_TEST),\n",
    "    malicious_ds=range(N_MALICIOUS_TRAIN + 1, N_MALICIOUS_TRAIN + 1 + N_HARM_TEST // 2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fda651",
   "metadata": {},
   "source": [
    "## Set of $R_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafb78d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_full_block_activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m harmful_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mget_full_block_activations\u001b[49m(model, tokenizer, harm_test)\n\u001b[0;32m      2\u001b[0m harmless_vectors \u001b[38;5;241m=\u001b[39m get_full_block_activations(model,tokenizer, clean_test)\n\u001b[0;32m      3\u001b[0m refusal_vectors \u001b[38;5;241m=\u001b[39m get_refusal_vectors(harmful_vectors, harmless_vectors)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_full_block_activations' is not defined"
     ]
    }
   ],
   "source": [
    "harmful_vectors = get_full_block_activations(model, tokenizer, harm_train)\n",
    "harmless_vectors = get_full_block_activations(model, tokenizer, clean_train)\n",
    "refusal_vectors = get_refusal_vectors(harmful_vectors, harmless_vectors)\n",
    "\n",
    "r1_save_filename = save_candidate_vectors(f\"Data\\{model_name.replace(\"/\", \"_\")}_r1.pt\", refusal_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b3240",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_results = run_experiment_batch(\n",
    "    harm_test,\n",
    "    clean_test,\n",
    "    refusal_vectors,\n",
    "    model,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803382be",
   "metadata": {},
   "outputs": [],
   "source": [
    "unload_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b58a0e",
   "metadata": {},
   "source": [
    "### Load Saftey model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cec86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "saftey_model_name = \"meta-llama/Meta-Llama-Guard-2-8B\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # stable low-precision compute\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load tokenizer + model\n",
    "guard_tokenizer = AutoTokenizer.from_pretrained(saftey_model_name , trust_remote_code=True)\n",
    "\n",
    "guard_model = AutoModelForCausalLM.from_pretrained(\n",
    "    saftey_model_name ,\n",
    "    quantization_config=quant_config,\n",
    "    device_map=device,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "if guard_tokenizer.pad_token is None:\n",
    "    guard_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    guard_model.resize_token_embeddings(len(guard_tokenizer))\n",
    "\n",
    "guard_tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd0231",
   "metadata": {},
   "source": [
    "### Saftey Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446afad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'moderate_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmoderate_batch\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'moderate_batch' is not defined"
     ]
    }
   ],
   "source": [
    "safety_scores = safety_score(guard_tokenizer, guard_model, r1_results[\"Prompt\"], r1_results[\"Output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
