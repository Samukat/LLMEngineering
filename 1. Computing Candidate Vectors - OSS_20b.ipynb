{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b360db9",
   "metadata": {},
   "source": [
    "## Notebook 1: Computing Candidate Refusal Vectors\n",
    "In this notebook, we record the model's activations on harmful and harmless generations. We then take the difference of these activations at many different token positions and layers to find a set of candidate refusal vectors. These are stored in the data folder of this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202a973-a229-41d8-90f5-d4ee02fc0c99",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf57f23-3394-49ff-81e1-bcec7d4c53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "from transformers import GenerationConfig\n",
    "from functools import partial\n",
    "import accelerate\n",
    "import torch\n",
    "from RefusalVectors import load_benchmarks, get_full_block_activations, get_refusal_vectors, save_candidate_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32f751-0f36-4e09-a40d-d6a9e82ca46e",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd1cd3c-88f8-4137-9efa-42842af18353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MXFP4 quantization requires triton >= 3.4.0 and kernels installed, we will default to dequantizing the model to bf16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94afd641a1f942c6bfa990e44fed289d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/gpt-oss-20b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"openai/gpt-oss-20b\", \n",
    "    trust_remote_code=True,\n",
    "    # device_map=\"auto\",   # Hugging Face accelerates across multiple GPUs\n",
    "    dtype=\"auto\"   # or torch.float16 / bfloat16\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af22bc",
   "metadata": {},
   "source": [
    "## Download the prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73dae40-af7e-4550-b73d-a7e9debeee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "harm_train, clean_train = load_benchmarks(harm_range = range(150), alpaca_range = range(200), malicious_range = range(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28612b-92e8-40cf-b90a-ee8425cfa5c2",
   "metadata": {},
   "source": [
    "## Clear previous hooks and get activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be5aec-a37d-408b-b986-c45dc5334032",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in model.modules():\n",
    "    module._forward_hooks.clear()\n",
    "    module._forward_pre_hooks.clear()\n",
    "    module._backward_hooks.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8d7a1-8374-43ea-a15d-e8ebde277051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:27<00:00,  2.29it/s]\n",
      "100%|██████████| 200/200 [01:29<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "harmful_vectors = get_full_block_activations(model, harm_train)\n",
    "harmless_vectors = get_full_block_activations(model, clean_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6024cd6-e62d-4e97-8c81-b265786b6daf",
   "metadata": {},
   "source": [
    "## Subtracting the Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266a1a1-3284-4368-b0ec-e7185aa01337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.18it/s]\n"
     ]
    }
   ],
   "source": [
    "refusal_vectors = get_refusal_vectors(harmful_vectors, harmless_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b8083-5aca-4fce-87d0-a48277da4b42",
   "metadata": {},
   "source": [
    "## Saving The Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c87c48-4ae0-4a5a-9788-e9f1b90a909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_candidate_vectors(\"Data\\oss_refusal_vectors.pt\", refusal_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
